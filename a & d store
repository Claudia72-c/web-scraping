from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
import pandas as pd
import re
import time
from datetime import datetime

# ========================
# CONFIGURATION
# ========================
CATEGORIES = [
    ("Paint", "https://aanddstore.co.ke/category/paints/"),
    ("Cement", "https://aanddstore.co.ke/category/building-materials/cement"),
    ("Tiles", "https://aanddstore.co.ke/category/tile-and-sanitary/floor-wall-tiles"),
    ("Plumbing", "https://aanddstore.co.ke/category/pipes-and-plumbing"),
    ("Tanks", "https://aanddstore.co.ke/category/building-materials/tanks")
]

# Format: day-month-year
TIMESTAMP = datetime.now().strftime('%d-%m-%Y')
FILE_NAME = f"a_&_d_hardware_{TIMESTAMP}.xlsx"

# ========================
# SELENIUM DRIVER SETUP
# ========================
def setup_driver():
    options = Options()
    options.add_argument("--start-maximized")
    options.add_argument("--disable-notifications")
    options.add_argument("--disable-popup-blocking")
    driver = webdriver.Chrome(options=options)
    driver.set_page_load_timeout(180)
    return driver

# ========================
# SCRAPING FUNCTION
# ========================
def scrape_category(driver, category_name, category_url):
    print(f"\nüîç Scraping category: {category_name}")
    products = []
    page_number = 1

    while True:
        page_url = category_url if page_number == 1 else f"{category_url}?page={page_number}"
        try:
            driver.get(page_url)
        except Exception as e:
            print(f"‚ö†Ô∏è Error loading page {page_number}: {str(e)} ‚Äî skipping.")
            break

        time.sleep(5)
        soup = BeautifulSoup(driver.page_source, "html.parser")
        product_cards = soup.select("a.rounded-md.shadow-sm.hover\\:shadow-md.transition-shadow.border.border-blue-100.p-1")

        if not product_cards:
            print(f"‚úÖ No more products found on page {page_number}.")
            break

        print(f"‚úÖ Found {len(product_cards)} products on page {page_number}")

        for card in product_cards:
            try:
                name_tag = card.find("h3")
                price_tag = card.find("span", class_="font-medium")
                name = name_tag.get_text(strip=True) if name_tag else None
                price = price_tag.get_text(strip=True) if price_tag else None

                if name and price:
                    products.append({
                        "Category": category_name,
                        "Product Name": name,
                        "Price": price
                    })

            except Exception as e:
                print(f"‚ö†Ô∏è Error extracting product: {str(e)}")
                continue

        page_number += 1

    return products

# ========================
# SPLIT PRODUCT DETAILS
# ========================
def split_product_details(full_name):
    if not isinstance(full_name, str):
        return pd.Series({'Product_Name': None, 'Quantity': None})

    quantity_pattern = r'(?i)(\d+(?:\.\d+)?)\s*(ml|l|g|kg|pcs|pack|pieces|grams|kilos)'
    quantity_match = re.search(quantity_pattern, full_name)

    if quantity_match:
        qty_value = quantity_match.group(1)
        qty_unit = quantity_match.group(2).upper()
        quantity = f"{qty_value}{qty_unit}"
        product_name = re.split(quantity_pattern, full_name, maxsplit=1, flags=re.IGNORECASE)[0].strip()
    else:
        product_name = full_name
        quantity = None

    return pd.Series({
        'Product_Name': product_name,
        'Quantity': quantity
    })

# ========================
# MAIN FUNCTION
# ========================
def main():
    driver = setup_driver()
    all_products = []

    try:
        for cat_name, cat_url in CATEGORIES:
            products = scrape_category(driver, cat_name, cat_url)
            all_products.extend(products)

        if all_products:
            df = pd.DataFrame(all_products)

            # Split product name & quantity
            details_df = df['Product Name'].apply(split_product_details)
            df_final = pd.concat([df[['Category']], details_df, df[['Price']]], axis=1)

            # Drop rows with missing values
            df_final.dropna(inplace=True)

            # Save to Excel
            with pd.ExcelWriter(FILE_NAME, engine='openpyxl') as writer:
                sheet_name = FILE_NAME.replace('.xlsx', '')[:31]
                df_final.to_excel(writer, sheet_name=sheet_name, index=False)

            print(f"\n‚úÖ Final product data saved to: {FILE_NAME}")

        else:
            print("‚ö†Ô∏è No products found.")

    finally:
        driver.quit()
        print("Browser closed.")

if __name__ == "__main__":
    main()
